{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIBTqlGrK3RD7u7ZkednVR"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced KNN from Scratch  \n",
        "**Author:** Aman (Documenting my ML learning journey)\n",
        "\n",
        "\"\"\"  \n",
        "In this notebook, I am taking my KNN understanding one step deeper.  \n",
        "The goal is not just to use `KNeighborsClassifier` from sklearn,  \n",
        "but to explore **variations, improvements, and practical challenges** of KNN.  \n",
        "\n",
        "What I will cover here:  \n",
        "- **Effect of Feature Scaling** — why KNN needs scaling and how accuracy changes without it.  \n",
        "- **Weighted KNN** — giving closer neighbors more importance than distant ones.  \n",
        "- **Different Distance Metrics** — Euclidean, Manhattan, Minkowski, etc.  \n",
        "- **Handling Imbalanced Data** — what happens to KNN when data is skewed and how to fix it.  \n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "bLrnRYwSnOP6"
      }
    }
  ]
}